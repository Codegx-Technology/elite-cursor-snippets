#!/usr/bin/env python3
"""
üé® Cartoon/Anime Pipeline - African Animation Studio
Lightweight, CPU-friendly pipeline for cartoon/anime videos with African identity

// [SNIPPET]: thinkwithai + kenyafirst + refactorclean + surgicalfix
// [CONTEXT]: Separate cartoon/anime pipeline with African cultural elements
// [GOAL]: CPU-friendly animation with Sheng/Kiswahili TTS and mobile exports
"""

import torch
from diffusers import AutoPipelineForText2Image
import cv2
import numpy as np
from pathlib import Path
import time
import json
import subprocess
from typing import List, Dict, Optional

class AfricanCartoonPipeline:
    """
    üé® African Cartoon/Anime Video Generator
    
    Features:
    - CPU-friendly cartoon generation
    - African cultural elements
    - Sheng/Kiswahili TTS support
    - Mobile export presets
    - Batch processing from CSV
    """
    
    def __init__(self):
        self.output_folder = Path("cartoon_studio")
        self.output_folder.mkdir(exist_ok=True)
        
        # Animation settings
        self.fps = 24  # Standard animation FPS
        self.width = 1280
        self.height = 720
        
        # Cartoon style presets
        self.cartoon_styles = {
            "african_cartoon": {
                "base_prompt": "African cartoon style, vibrant colors, traditional attire, beautiful landscapes",
                "negative": "realistic, photographic, dark, gloomy"
            },
            "anime": {
                "base_prompt": "anime style, manga art, colorful, expressive characters",
                "negative": "realistic, western cartoon, 3D"
            },
            "kenyan_animation": {
                "base_prompt": "Kenyan animation style, Maasai patterns, savanna background, cultural clothing",
                "negative": "western style, modern city, foreign elements"
            }
        }
        
        # TTS language options
        self.tts_languages = {
            "sheng_male": {"lang": "sw", "voice": "male", "speed": 1.0},
            "sheng_female": {"lang": "sw", "voice": "female", "speed": 1.0},
            "kiswahili": {"lang": "sw", "voice": "neutral", "speed": 0.9},
            "english_news": {"lang": "en", "voice": "news", "speed": 1.1}
        }
        
        # Mobile export presets
        self.export_presets = {
            "tiktok": {"width": 720, "height": 1280, "fps": 30, "duration": 60},
            "whatsapp": {"width": 720, "height": 720, "fps": 24, "duration": 30},
            "youtube_shorts": {"width": 720, "height": 1280, "fps": 30, "duration": 60},
            "instagram_reel": {"width": 720, "height": 1280, "fps": 30, "duration": 30}
        }
        
        print("üé® AFRICAN CARTOON PIPELINE INITIALIZED")
        print(f"üìÅ Studio folder: {self.output_folder.absolute()}")
        print(f"üé¨ Styles: {list(self.cartoon_styles.keys())}")
        print(f"üé§ Languages: {list(self.tts_languages.keys())}")
        print(f"üì± Export presets: {list(self.export_presets.keys())}")
    
    def load_cartoon_model(self, style: str = "african_cartoon"):
        """Load appropriate model for cartoon generation"""
        
        try:
            print(f"ü§ñ Loading cartoon model for {style}...")
            
            # Use SDXL-Turbo as base (already cached)
            # In production, we'd use anything-v4.5 or cartoon-specific models
            pipe = AutoPipelineForText2Image.from_pretrained(
                "stabilityai/sdxl-turbo",
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                variant="fp16" if torch.cuda.is_available() else None,
                use_safetensors=True,
                low_cpu_mem_usage=True
            )
            
            if torch.cuda.is_available():
                pipe = pipe.to("cuda")
                print("üî• GPU acceleration for cartoon generation")
            else:
                print("üñ•Ô∏è CPU mode - optimized for cartoon style")
            
            print("‚úÖ Cartoon model ready")
            return pipe
            
        except Exception as e:
            print(f"‚ùå Cartoon model loading failed: {e}")
            return None
    
    def break_script_into_scenes(self, script: str) -> List[Dict]:
        """Break script into cartoon scenes with dialogue"""
        
        print("üìù Breaking script into cartoon scenes...")
        
        # Simple scene breakdown (in production, use GPT)
        sentences = script.split('. ')
        scenes = []
        
        for i, sentence in enumerate(sentences[:5]):  # Limit to 5 scenes
            if sentence.strip():
                scene = {
                    "id": i + 1,
                    "dialogue": sentence.strip() + ".",
                    "visual_description": f"African cartoon scene {i+1}: {sentence[:50]}...",
                    "duration": 3.0,  # 3 seconds per scene
                    "character_emotion": "happy" if i % 2 == 0 else "thoughtful"
                }
                scenes.append(scene)
        
        print(f"‚úÖ Created {len(scenes)} cartoon scenes")
        return scenes
    
    def generate_cartoon_scene(self, pipe, scene: Dict, style: str) -> Optional[np.ndarray]:
        """Generate single cartoon scene image"""
        
        print(f"üé® Generating cartoon scene {scene['id']}: {scene['visual_description'][:40]}...")
        
        try:
            # Build cartoon prompt
            style_config = self.cartoon_styles[style]
            
            prompt = f"""
            {style_config['base_prompt']}, 
            {scene['visual_description']}, 
            {scene['character_emotion']} expression,
            bright colors, clean lines, cartoon style,
            African setting, cultural elements
            """.strip().replace('\n', ' ')
            
            negative_prompt = style_config['negative']
            
            print(f"üìù Prompt: {prompt[:60]}...")
            
            # Generate cartoon image
            image = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=2,  # Fast for cartoons
                guidance_scale=0.0,
                height=self.height,
                width=self.width
            ).images[0]
            
            # Save scene image
            scene_path = self.output_folder / f"scene_{scene['id']:02d}_cartoon.png"
            image.save(scene_path)
            
            file_size = scene_path.stat().st_size / 1024
            print(f"‚úÖ Scene {scene['id']} generated: {file_size:.1f} KB")
            
            # Convert to OpenCV format
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            return cv_image
            
        except Exception as e:
            print(f"‚ùå Scene {scene['id']} generation failed: {e}")
            return None
    
    def create_scene_animation(self, scene_image: np.ndarray, duration: float) -> List[np.ndarray]:
        """Create simple animation from static scene"""
        
        print(f"üé¨ Creating {duration}s animation...")
        
        frames = []
        total_frames = int(self.fps * duration)
        
        for frame_num in range(total_frames):
            frame = scene_image.copy()
            progress = frame_num / total_frames
            
            # Simple animation effects
            # 1. Subtle zoom
            zoom_factor = 1.0 + (np.sin(progress * np.pi * 2) * 0.02)
            
            # 2. Slight pan
            pan_x = int(np.sin(progress * np.pi) * 10)
            pan_y = int(np.cos(progress * np.pi) * 5)
            
            # Apply transformations
            h, w = frame.shape[:2]
            
            # Zoom
            crop_w = int(w / zoom_factor)
            crop_h = int(h / zoom_factor)
            x1 = max(0, (w - crop_w) // 2 + pan_x)
            y1 = max(0, (h - crop_h) // 2 + pan_y)
            x2 = min(w, x1 + crop_w)
            y2 = min(h, y1 + crop_h)
            
            cropped = frame[y1:y2, x1:x2]
            animated_frame = cv2.resize(cropped, (w, h))
            
            frames.append(animated_frame)
        
        print(f"‚úÖ Created {len(frames)} animated frames")
        return frames
    
    def generate_african_tts(self, text: str, voice: str = "sheng_male") -> Optional[str]:
        """Generate TTS audio in African languages"""
        
        print(f"üé§ Generating {voice} TTS for: {text[:30]}...")
        
        try:
            # Placeholder for TTS generation
            # In production: integrate Bark, PiperTTS, or Coqui TTS
            
            audio_path = self.output_folder / f"tts_{voice}_{int(time.time())}.wav"
            
            # Create simple tone sequence for now (replace with real TTS)
            sample_rate = 22050
            duration = len(text) * 0.1  # Rough estimate
            
            # Generate speech-like tones
            frames = []
            for i in range(int(sample_rate * duration)):
                # Create speech-like frequency modulation
                base_freq = 150 if "male" in voice else 200
                freq = base_freq + np.sin(i * 0.01) * 50
                
                value = int(16384 * np.sin(2 * np.pi * freq * i / sample_rate))
                frames.append(value.to_bytes(2, 'little', signed=True))
            
            # Save as WAV
            import wave
            with wave.open(str(audio_path), 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(b''.join(frames))
            
            print(f"‚úÖ TTS audio: {audio_path}")
            return str(audio_path)
            
        except Exception as e:
            print(f"‚ùå TTS generation failed: {e}")
            return None
    
    def create_cartoon_video(self, scenes: List[Dict], style: str, voice: str) -> Optional[str]:
        """Create complete cartoon video"""
        
        print(f"üé¨ Creating cartoon video: {style} style, {voice} voice")
        
        # Load cartoon model
        pipe = self.load_cartoon_model(style)
        if pipe is None:
            return None
        
        # Generate all scenes
        all_frames = []
        all_audio_paths = []
        
        for scene in scenes:
            # Generate scene image
            scene_image = self.generate_cartoon_scene(pipe, scene, style)
            if scene_image is None:
                continue
            
            # Create animation
            animated_frames = self.create_scene_animation(scene_image, scene['duration'])
            all_frames.extend(animated_frames)
            
            # Generate TTS
            audio_path = self.generate_african_tts(scene['dialogue'], voice)
            if audio_path:
                all_audio_paths.append(audio_path)
        
        if not all_frames:
            print("‚ùå No frames generated")
            return None
        
        # Create video
        video_path = self.output_folder / f"cartoon_{style}_{voice}_{int(time.time())}.mp4"
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(str(video_path), fourcc, self.fps, (self.width, self.height))
        
        print(f"üìπ Writing {len(all_frames)} frames...")
        
        for frame in all_frames:
            writer.write(frame)
        
        writer.release()
        
        if video_path.exists():
            size_mb = video_path.stat().st_size / (1024*1024)
            print(f"‚úÖ Cartoon video created: {size_mb:.1f} MB")
            return str(video_path)
        else:
            print("‚ùå Video creation failed")
            return None
    
    def export_for_mobile(self, video_path: str, preset: str) -> Optional[str]:
        """Export video for mobile platforms"""
        
        if preset not in self.export_presets:
            print(f"‚ùå Unknown preset: {preset}")
            return None
        
        config = self.export_presets[preset]
        output_path = self.output_folder / f"mobile_{preset}_{int(time.time())}.mp4"
        
        try:
            cmd = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-vf", f"scale={config['width']}:{config['height']}",
                "-r", str(config['fps']),
                "-t", str(config['duration']),
                "-c:v", "libx264",
                "-preset", "fast",
                "-crf", "23",
                str(output_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and output_path.exists():
                print(f"‚úÖ Mobile export ({preset}): {output_path}")
                return str(output_path)
            else:
                print(f"‚ùå Mobile export failed: {result.stderr}")
                return None
                
        except Exception as e:
            print(f"‚ùå Export error: {e}")
            return None


def create_african_cartoon_video(
    script: str,
    style: str = "african_cartoon",
    voice: str = "sheng_male",
    mobile_preset: Optional[str] = None
) -> Dict:
    """
    Main function to create African cartoon video
    
    Args:
        script: Text script to animate
        style: Cartoon style (african_cartoon, anime, kenyan_animation)
        voice: TTS voice (sheng_male, sheng_female, kiswahili, english_news)
        mobile_preset: Export preset (tiktok, whatsapp, youtube_shorts, instagram_reel)
    
    Returns:
        Dict with video paths and metadata
    """
    
    print("üé® AFRICAN CARTOON VIDEO GENERATOR")
    print("=" * 50)
    
    pipeline = AfricanCartoonPipeline()
    
    # Break script into scenes
    scenes = pipeline.break_script_into_scenes(script)
    
    # Create cartoon video
    video_path = pipeline.create_cartoon_video(scenes, style, voice)
    
    result = {
        "success": video_path is not None,
        "video_path": video_path,
        "scenes": len(scenes),
        "style": style,
        "voice": voice
    }
    
    # Mobile export if requested
    if mobile_preset and video_path:
        mobile_path = pipeline.export_for_mobile(video_path, mobile_preset)
        result["mobile_path"] = mobile_path
        result["mobile_preset"] = mobile_preset
    
    return result


if __name__ == "__main__":
    # Test the cartoon pipeline
    test_script = """
    Welcome to Kenya, the beautiful land of diverse cultures. 
    Mount Kenya stands majestically with snow-capped peaks. 
    The Maasai people preserve their rich traditions. 
    Wildlife roams freely in the vast savannas. 
    This is our home, this is Kenya.
    """
    
    result = create_african_cartoon_video(
        script=test_script,
        style="african_cartoon",
        voice="sheng_male",
        mobile_preset="tiktok"
    )
    
    print(f"\nüéâ RESULT: {result}")
